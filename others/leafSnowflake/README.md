
# Leaf-Snowflake (Go Implementation)

This is a production-grade **Distributed Unique ID Generator**.

It is based on Twitter's **Snowflake Algorithm**, utilizes **Zookeeper** as a registry center to automatically assign and manage `WorkerID`s (solving the pain point of manual assignment in traditional Snowflake implementations), and implements robust **Clock Rollback Protection**.

## ðŸ“– Table of Contents

1.  [Background: Snowflake Algorithm](https://www.google.com/search?q=%231-background-snowflake-algorithm)
2.  [Core Features](https://www.google.com/search?q=%232-core-features)
3.  [Code Deep Dive](https://www.google.com/search?q=%233-code-deep-dive)
      - [ID Structure Definition](https://www.google.com/search?q=%2331-id-structure-definition)
      - [WorkerID Automatic Registration & Recovery](https://www.google.com/search?q=%2332-workerid-automatic-registration--recovery)
      - [Core Generation Logic (NextID)](https://www.google.com/search?q=%2333-core-generation-logic-nextid)
      - [Clock Rollback Protection](https://www.google.com/search?q=%2334-clock-rollback-protection)
4.  [Quick Start](https://www.google.com/search?q=%234-quick-start)
5.  [FAQ](https://www.google.com/search?q=%235-faq)

-----

## 1\. Background: Snowflake Algorithm

[Image of Snowflake ID structure]

The ID generated by the Snowflake algorithm is a 64-bit integer (`int64`) with the following structure (based on the configuration in this code):

  * **1 bit**: Unused (Sign bit, always 0 to ensure the ID is positive).
  * **41 bits**: Millisecond-level timestamp (Usable for approximately 69 years).
  * **10 bits**: WorkerID (Machine ID). Supports deploying up to 1024 nodes ($2^{10}$).
  * **12 bits**: Sequence Number. Generates up to 4096 IDs per millisecond ($2^{12}$).

**Advantages**:

  * The generated IDs are roughly ordered by time (optimal for database indexing).
  * No database dependency; generated entirely in memory for high performance.
  * Guaranteed uniqueness in a distributed environment.

-----

## 2\. Core Features

Compared to the original Snowflake algorithm, this implementation adds the following engineering features:

1.  **Zookeeper Integration**: Uses ZK persistent nodes to record `WorkerID`s. Nodes retain the same ID after restarting.
2.  **Dual Disaster Recovery**:
      * If ZK is unavailable, it attempts to recover from the local file system (**Local Cache**).
      * If the local file is also missing, it uses a fallback algorithm to assign an ID.
3.  **Clock Rollback Protection**:
      * **At Startup**: Checks if the current system time is earlier than the last recorded time (in ZK or Cache).
      * **At Runtime**: If a time rollback is detected, it refuses to generate IDs or waits for the time to catch up.

-----

## 3\. Code Deep Dive

### 3.1 ID Structure Definition

The "skeleton" of the algorithm is defined at the top of the code:

```go
const (
    Epoch int64 = 1672531200000 // Start Time (2023-01-01)
    
    WorkerIdBits = 10 // Bits for Worker ID
    SequenceBits = 12 // Bits for Sequence
    // ... Bit shift calculations ...
)
```

**Analysis**:

  * `Epoch` is a custom starting timestamp. The 41-bit timestamp records the delta of `CurrentTime - Epoch`.
  * Bitwise Shift operations are used to splice the Time, WorkerID, and Sequence into a single 64-bit integer.

### 3.2 WorkerID Automatic Registration & Recovery

This is the highlight of this implementation. The `registerOrRecover` function is responsible for determining which `WorkerID` the current node should use.

**Logic Flow**:

1.  **Build ZK Path**: `/leaf_snowflake/{serviceName}/{port}`.
2.  **Check ZK**:
      * **Node Exists**: Read data to recover the `WorkerID`. Simultaneously checks if `LastTime` (last heartbeat) is greater than the current time (detecting clock rollback).
      * **Node Does Not Exist**: Implies a new machine or lost ZK data.
3.  **Fallback Strategy**:
      * Attempt to read the local file `.leaf_cache_{port}`.
      * If the file is missing, calculate a fallback ID using `port % 1024`.
4.  **Register/Update**: Write the determined `WorkerID` and current time to ZK and save it to the local file.

**Code Snippet**:

```go
// Check if system clock moved backwards (Critical safety check)
if currentTime < myNodeInfo.LastTime {
    return 0, fmt.Errorf("clock moved backwards...")
}
```

### 3.3 Core Generation Logic (NextID)

The `NextID` method is the core bottleneck under high concurrency. It uses `sync.Mutex` to ensure thread safety.

**Logic Flow**:

1.  **Get Current Millisecond**.
2.  **Within the Same Millisecond**:
      * Increment `sequence + 1`.
      * If the sequence overflows (exceeds 4095), spin/busy-wait for the next millisecond.
3.  **New Millisecond**:
      * Reset `sequence` to 0.
4.  **Bitwise Assembly**:
    ```go
    id := ((now - Epoch) << TimestampShift) |
          (d.workerID << WorkIdShift) |
          d.sequence
    ```

### 3.4 Clock Rollback Protection

Snowflake algorithms are most vulnerable to server time rollbacks (e.g., NTP automatic calibration), which can lead to duplicate IDs.

**Runtime Protection**:
Inside `NextID`:

```go
if now < d.lastTime {
    offset := d.lastTime - now
    if offset <= 5 {
        // If the rollback is small, pause briefly to let time catch up
        time.Sleep(...)
    } else {
        // If rollback is severe, return error and refuse service to protect data consistency
        return 0, fmt.Errorf("clock moved backwards too much")
    }
}
```

**Background Heartbeat (`scheduledUploadTime`)**:
Every 3 seconds, a background Goroutine updates the current timestamp to Zookeeper and the local file. This ensures that if the service restarts, we know the last time the service was alive, allowing us to detect time anomalies immediately upon startup.

-----

## 4\. Quick Start

### Prerequisites

You need a running Zookeeper instance.

```bash
# Start local Zookeeper using Docker
docker run --name some-zookeeper -p 2181:2181 -d zookeeper
```

### Running the Code

1.  Save the code as `main.go`.
2.  Install dependencies:
    ```bash
    go get github.com/go-zookeeper/zk
    ```
3.  Run the program:
    ```bash
    go run main.go
    ```

### Expected Output

```text
snowflake driver initialized with workerID: 888  <-- Automatically assigned ID
Start generating IDs...
Done.
```

You will also notice a `.leaf_cache_8080` file generated in the directory, which serves as the local cache.

-----

## 5\. FAQ

**Q: Why is the local file cache necessary?**
A: If the Zookeeper cluster goes down, the application cannot connect to ZK to get a `WorkerID` during a restart. In this case, the local file cache acts as an "escape pod," allowing the service to restart using its previously assigned `WorkerID`.

**Q: What is the purpose of SequenceMask?**
A: `SequenceMask` (value 4095, binary `111111111111`) is used for bitwise AND operations: `(sequence + 1) & SequenceMask`. This is a highly efficient modulo operation. When the sequence reaches 4096, the result automatically wraps around to 0.